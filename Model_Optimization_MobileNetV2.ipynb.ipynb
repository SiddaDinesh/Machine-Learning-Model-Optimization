{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1yx7MLYaKF818BUBfFLbli_uz_YVwmgSC","authorship_tag":"ABX9TyO7KXPBWJh9qHa9500BG8z9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EDuUVpNRCZDv","executionInfo":{"status":"ok","timestamp":1767582750067,"user_tz":-330,"elapsed":2886,"user":{"displayName":"Sidda Dinesh","userId":"17618019657411610287"}},"outputId":"f405e4ae-e70f-49b4-f0f9-4a653c79ae9c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["!pip install torch torchvision onnx onnxruntime psutil pillow numpy\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lPXl5azJCr3f","executionInfo":{"status":"ok","timestamp":1767582754246,"user_tz":-330,"elapsed":4170,"user":{"displayName":"Sidda Dinesh","userId":"17618019657411610287"}},"outputId":"e6f89f4a-5436-4b2e-df83-b4d407378ed4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.1)\n","Requirement already satisfied: onnx in /usr/local/lib/python3.12/dist-packages (1.20.0)\n","Requirement already satisfied: onnxruntime in /usr/local/lib/python3.12/dist-packages (1.23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (5.9.5)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.3.83)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.9.90)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.3.90)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.8.93)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n","Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1.3)\n","Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.1)\n","Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n","Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.4)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.9.23)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime) (10.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"]}]},{"cell_type":"code","source":["import torch\n","import torchvision.models as models\n","\n","# Load pre-trained MobileNetV2\n","model = models.mobilenet_v2(pretrained=True)\n","\n","# Set model to evaluation mode\n","model.eval()\n","\n","print(\"MobileNetV2 loaded successfully\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0pDclu-EDGy4","executionInfo":{"status":"ok","timestamp":1767582760863,"user_tz":-330,"elapsed":6610,"user":{"displayName":"Sidda Dinesh","userId":"17618019657411610287"}},"outputId":"025071ae-3d8d-4bce-a5c3-0d1ff2d7fe47"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["MobileNetV2 loaded successfully\n"]}]},{"cell_type":"code","source":["import torchvision.transforms as transforms\n","from PIL import Image\n","\n","def preprocess_image(image_path):\n","    transform = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(\n","            mean=[0.485, 0.456, 0.406],\n","            std=[0.229, 0.224, 0.225]\n","        )\n","    ])\n","\n","    img = Image.open(image_path).convert(\"RGB\")\n","    return transform(img).unsqueeze(0)\n","\n","# Mount Google Drive (run once)\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Your image path\n","image_path = \"/content/drive/MyDrive/sample.jpg\"\n","\n","# Load input image\n","input_tensor = preprocess_image(image_path)\n","\n","print(\"Image preprocessed successfully\")\n","print(\"Input shape:\", input_tensor.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IGuR42oIENAm","executionInfo":{"status":"ok","timestamp":1767582762870,"user_tz":-330,"elapsed":2000,"user":{"displayName":"Sidda Dinesh","userId":"17618019657411610287"}},"outputId":"6caef553-c434-4e8f-d0e3-e7583f82e61f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Image preprocessed successfully\n","Input shape: torch.Size([1, 3, 224, 224])\n"]}]},{"cell_type":"code","source":["import time\n","import os\n","import psutil\n","import numpy as np\n","\n","def measure_inference_time(model, input_tensor, runs=10):\n","    times = []\n","    with torch.no_grad():\n","        for _ in range(runs):\n","            start = time.time()\n","            _ = model(input_tensor)\n","            end = time.time()\n","            times.append((end - start) * 1000)  # ms\n","    return np.mean(times)\n"],"metadata":{"id":"VoiVk4ogFokS","executionInfo":{"status":"ok","timestamp":1767582762882,"user_tz":-330,"elapsed":6,"user":{"displayName":"Sidda Dinesh","userId":"17618019657411610287"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["process = psutil.Process(os.getpid())\n","\n","# Memory before inference\n","mem_before = process.memory_info().rss / (1024 * 1024)\n","\n","# Measure inference time\n","original_inference_time = measure_inference_time(model, input_tensor)\n","\n","# Memory after inference\n","mem_after = process.memory_info().rss / (1024 * 1024)\n","\n","print(f\"Original Inference Time (ms): {original_inference_time:.2f}\")\n","print(f\"Original Memory Usage (MB): {mem_after - mem_before:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ULJ2iQ05GE01","executionInfo":{"status":"ok","timestamp":1767582763305,"user_tz":-330,"elapsed":417,"user":{"displayName":"Sidda Dinesh","userId":"17618019657411610287"}},"outputId":"0216b0d8-4f8a-4502-fc95-3f68f237ca13"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Inference Time (ms): 50.78\n","Original Memory Usage (MB): 16.21\n"]}]},{"cell_type":"code","source":["# Save model to measure size\n","torch.save(model.state_dict(), \"original_model.pth\")\n","\n","original_model_size = os.path.getsize(\"original_model.pth\") / (1024 * 1024)\n","\n","print(f\"Original Model Size (MB): {original_model_size:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DAIakFZBGHYf","executionInfo":{"status":"ok","timestamp":1767582763385,"user_tz":-330,"elapsed":75,"user":{"displayName":"Sidda Dinesh","userId":"17618019657411610287"}},"outputId":"a0fd35d9-dc35-46cc-f77c-6adb2fcddec2"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Model Size (MB): 13.60\n"]}]},{"cell_type":"code","source":["print(\"Accuracy: ~71.8% (ImageNet Top-1, MobileNetV2)\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4YKfuv6AGOEe","executionInfo":{"status":"ok","timestamp":1767582763438,"user_tz":-330,"elapsed":48,"user":{"displayName":"Sidda Dinesh","userId":"17618019657411610287"}},"outputId":"eed95299-9332-4362-e584-a6e85feb06ef"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: ~71.8% (ImageNet Top-1, MobileNetV2)\n"]}]},{"cell_type":"code","source":["# Convert model to FP16\n","model_fp16 = model.half()\n","\n","# Convert input tensor to FP16\n","input_tensor_fp16 = input_tensor.half()\n","\n","print(\"FP16 quantization applied successfully\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AEGcjmuxGiJt","executionInfo":{"status":"ok","timestamp":1767582763466,"user_tz":-330,"elapsed":8,"user":{"displayName":"Sidda Dinesh","userId":"17618019657411610287"}},"outputId":"222174e0-8eee-4341-8c42-dd88c99b997b"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["FP16 quantization applied successfully\n"]}]},{"cell_type":"code","source":["# Memory before optimized inference\n","process = psutil.Process(os.getpid())\n","mem_before_opt = process.memory_info().rss / (1024 * 1024)\n","\n","# Measure inference time for FP16 model\n","optimized_inference_time = measure_inference_time(model_fp16, input_tensor_fp16)\n","\n","# Memory after optimized inference\n","mem_after_opt = process.memory_info().rss / (1024 * 1024)\n","\n","print(f\"Optimized Inference Time (ms): {optimized_inference_time:.2f}\")\n","print(f\"Optimized Memory Usage (MB): {mem_after_opt - mem_before_opt:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fdy3GnkpG_-R","executionInfo":{"status":"ok","timestamp":1767582770614,"user_tz":-330,"elapsed":7146,"user":{"displayName":"Sidda Dinesh","userId":"17618019657411610287"}},"outputId":"60d1f6ff-a4be-4114-f815-95fae62a1a52"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Optimized Inference Time (ms): 697.91\n","Optimized Memory Usage (MB): 9.09\n"]}]},{"cell_type":"code","source":["# Save optimized model to measure size\n","torch.save(model_fp16.state_dict(), \"optimized_model_fp16.pth\")\n","\n","optimized_model_size = os.path.getsize(\"optimized_model_fp16.pth\") / (1024 * 1024)\n","\n","print(f\"Optimized Model Size (MB): {optimized_model_size:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N2GYcCGHHCW-","executionInfo":{"status":"ok","timestamp":1767582770635,"user_tz":-330,"elapsed":16,"user":{"displayName":"Sidda Dinesh","userId":"17618019657411610287"}},"outputId":"fc298959-9612-43e9-f904-737fe9acbc58"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Optimized Model Size (MB): 6.85\n"]}]},{"cell_type":"code","source":["!pip install --upgrade torch torchvision onnx onnxruntime\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I3hc7-vYJQrR","executionInfo":{"status":"ok","timestamp":1767582803749,"user_tz":-330,"elapsed":4981,"user":{"displayName":"Sidda Dinesh","userId":"17618019657411610287"}},"outputId":"a06cfd72-4f6d-40d3-bf5f-2dcd96cdc344"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.1)\n","Requirement already satisfied: onnx in /usr/local/lib/python3.12/dist-packages (1.20.0)\n","Requirement already satisfied: onnxruntime in /usr/local/lib/python3.12/dist-packages (1.23.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.3.83)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.9.90)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.3.90)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.8.93)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n","Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1.3)\n","Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n","Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n","Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.4)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.9.23)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime) (10.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"]}]},{"cell_type":"code","source":["!pip install torch==2.0.1 torchvision==0.15.2 onnx==1.14.1 onnxruntime==1.15.1 onnxscript\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UMBiAaWlJnuE","executionInfo":{"status":"ok","timestamp":1767582897708,"user_tz":-330,"elapsed":3911,"user":{"displayName":"Sidda Dinesh","userId":"17618019657411610287"}},"outputId":"ea671b28-2a8c-4ab7-80e0-664b01fe11d6"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.0.1 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0, 2.9.0, 2.9.1)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.0.1\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["model_fp16\n","input_tensor_fp16\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WulgJiguJswH","executionInfo":{"status":"ok","timestamp":1767582920214,"user_tz":-330,"elapsed":43,"user":{"displayName":"Sidda Dinesh","userId":"17618019657411610287"}},"outputId":"b21cce18-5b00-4f72-8e2b-f082089be92c"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[[0.3823, 0.4851, 0.2966,  ..., 1.2217, 1.0674, 1.0156],\n","          [0.3481, 0.4680, 0.5020,  ..., 1.2383, 1.0498, 0.9990],\n","          [0.9473, 1.0674, 1.0674,  ..., 1.2217, 1.0840, 1.0332],\n","          ...,\n","          [0.7593, 0.9644, 0.8618,  ..., 1.2217, 1.2217, 1.2725],\n","          [0.9302, 0.9644, 0.9473,  ..., 0.9644, 1.2725, 1.0840],\n","          [1.0156, 0.8447, 1.1533,  ..., 1.0156, 1.2725, 0.5195]],\n","\n","         [[0.3628, 0.4502, 0.2402,  ..., 1.1504, 0.9932, 0.9404],\n","          [0.3276, 0.4502, 0.4678,  ..., 1.1680, 0.9580, 0.9053],\n","          [0.9404, 1.0635, 1.0459,  ..., 1.1504, 0.9932, 0.9404],\n","          ...,\n","          [0.6953, 0.9053, 0.8003,  ..., 1.2734, 1.3252, 1.3955],\n","          [0.8706, 0.9053, 0.8882,  ..., 1.0283, 1.3779, 1.2031],\n","          [0.9580, 0.7827, 1.0977,  ..., 1.0801, 1.3779, 0.6431]],\n","\n","         [[0.4265, 0.4961, 0.3044,  ..., 1.0889, 0.9321, 0.8970],\n","          [0.3394, 0.4614, 0.4788,  ..., 1.1064, 0.9492, 0.8970],\n","          [0.8799, 1.0020, 1.0020,  ..., 1.0889, 0.9844, 0.9492],\n","          ...,\n","          [0.4961, 0.7056, 0.6182,  ..., 1.2109, 1.1934, 1.2461],\n","          [0.6704, 0.7056, 0.7056,  ..., 0.9492, 1.2285, 1.0361],\n","          [0.7578, 0.5835, 0.9146,  ..., 1.0020, 1.2979, 0.5659]]]],\n","       dtype=torch.float16)"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":[],"metadata":{"id":"unls8ftJJssn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install onnxscript\n","\n","torch.onnx.export(\n","    model_fp16,\n","    input_tensor_fp16,\n","    \"optimized_model.onnx\",\n","    export_params=True,\n","    opset_version=11,\n","    do_constant_folding=True,\n","    input_names=[\"input\"],\n","    output_names=[\"output\"]\n",")\n","\n","print(\"ONNX model exported successfully (legacy exporter)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"krrYU-nrHQ4P","executionInfo":{"status":"ok","timestamp":1767583015313,"user_tz":-330,"elapsed":12472,"user":{"displayName":"Sidda Dinesh","userId":"17618019657411610287"}},"outputId":"2f8b6e57-1243-44b3-851f-050ca15c7732"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting onnxscript\n","  Downloading onnxscript-0.5.7-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnxscript) (0.5.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from onnxscript) (2.0.2)\n","Collecting onnx_ir<2,>=0.1.12 (from onnxscript)\n","  Downloading onnx_ir-0.1.13-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: onnx>=1.16 in /usr/local/lib/python3.12/dist-packages (from onnxscript) (1.20.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxscript) (25.0)\n","Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from onnxscript) (4.15.0)\n","Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx>=1.16->onnxscript) (5.29.5)\n","Downloading onnxscript-0.5.7-py3-none-any.whl (693 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.4/693.4 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnx_ir-0.1.13-py3-none-any.whl (133 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: onnx_ir, onnxscript\n","Successfully installed onnx_ir-0.1.13 onnxscript-0.5.7\n"]},{"output_type":"stream","name":"stderr","text":["W0105 03:16:48.092000 7871 torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 11 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"]},{"output_type":"stream","name":"stdout","text":["[torch.onnx] Obtain model graph for `MobileNetV2([...]` with `torch.export.export(..., strict=False)`...\n","[torch.onnx] Obtain model graph for `MobileNetV2([...]` with `torch.export.export(..., strict=False)`... ✅\n","[torch.onnx] Run decomposition...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:onnxscript.version_converter:The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 11).\n","WARNING:onnxscript.version_converter:Failed to convert the model to the target version 11 using the ONNX C API. The model was not modified\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/__init__.py\", line 127, in call\n","    converted_proto = _c_api_utils.call_onnx_api(\n","                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/_c_api_utils.py\", line 65, in call_onnx_api\n","    result = func(proto)\n","             ^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/__init__.py\", line 122, in _partial_convert_version\n","    return onnx.version_converter.convert_version(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/onnx/version_converter.py\", line 39, in convert_version\n","    converted_model_str = C.convert_version(model_str, target_version)\n","                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","RuntimeError: /github/workspace/onnx/version_converter/adapters/axes_input_to_attribute.h:65: adapt: Assertion `node->hasAttribute(kaxes)` failed: No initializer or constant input to node found\n"]},{"output_type":"stream","name":"stdout","text":["[torch.onnx] Run decomposition... ✅\n","[torch.onnx] Translate the graph into ONNX...\n","[torch.onnx] Translate the graph into ONNX... ✅\n","Applied 104 of general pattern rewrite rules.\n","ONNX model exported successfully (legacy exporter)\n"]}]},{"cell_type":"code","source":["onnx_model_size = os.path.getsize(\"optimized_model.onnx\") / (1024 * 1024)\n","print(f\"ONNX Model Size (MB): {onnx_model_size:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h3isAtxPHQ08","executionInfo":{"status":"ok","timestamp":1767583070410,"user_tz":-330,"elapsed":38,"user":{"displayName":"Sidda Dinesh","userId":"17618019657411610287"}},"outputId":"86da9ae4-7993-4a17-eef9-802f60405b23"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["ONNX Model Size (MB): 0.24\n"]}]},{"cell_type":"code","source":["import onnxruntime as ort\n","\n","session = ort.InferenceSession(\"optimized_model.onnx\")\n","\n","input_name = session.get_inputs()[0].name\n","output_name = session.get_outputs()[0].name\n","\n","# Convert input to numpy\n","input_numpy = input_tensor_fp16.cpu().numpy()\n","\n","start = time.time()\n","_ = session.run([output_name], {input_name: input_numpy})\n","end = time.time()\n","\n","print(\"ONNX Inference Time (ms):\", (end - start) * 1000)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IZaOxVpjKTZT","executionInfo":{"status":"ok","timestamp":1767583081508,"user_tz":-330,"elapsed":284,"user":{"displayName":"Sidda Dinesh","userId":"17618019657411610287"}},"outputId":"eaffa5dc-d343-451b-ae47-fca775ecf991"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["ONNX Inference Time (ms): 28.142213821411133\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"oBBPQ1vdKWEz"},"execution_count":null,"outputs":[]}]}